# ğŸ—ï¸ é¡¹ç›®æ¶æ„æ€»è§ˆ

## é¡¹ç›®ç®€ä»‹

NYLGï¼ˆNetwork Information Crawlerï¼‰æ˜¯ä¸€ä¸ªåŸºäºFlask + Vue.jsçš„ç°ä»£åŒ–ç½‘ç»œä¿¡æ¯çˆ¬å–ç³»ç»Ÿï¼Œé‡‡ç”¨å‰åç«¯åˆ†ç¦»æ¶æ„ï¼Œæ”¯æŒå¤šç§ç½‘ç«™çš„æ•°æ®é‡‡é›†å’Œå®æ—¶ä¸‹è½½åŠŸèƒ½ã€‚

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

- **å¤šå¹³å°çˆ¬è™«æ”¯æŒ**ï¼šç™¾åº¦æœç´¢ã€Bç«™è§†é¢‘ã€CSDNæ–‡ç« ã€è‡ªå®šä¹‰URL
- **å®æ—¶é€šä¿¡**ï¼šåŸºäºWebSocketçš„å®æ—¶ä»»åŠ¡çŠ¶æ€æ¨é€
- **ç°ä»£åŒ–å‰ç«¯**ï¼šVue 3 + Element Pluså“åº”å¼ç•Œé¢
- **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¸…æ™°çš„åˆ†å±‚æ¶æ„ï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤
- **æ™ºèƒ½å†…å®¹è¯†åˆ«**ï¼šè‡ªåŠ¨è¯†åˆ«ç½‘é¡µä¸­çš„æ–‡æœ¬ã€å›¾ç‰‡ã€è§†é¢‘ç­‰å†…å®¹

## ğŸ›ï¸ ç³»ç»Ÿæ¶æ„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å‰ç«¯å±‚ (Vue)   â”‚    â”‚   APIå±‚ (Flask) â”‚    â”‚   ä¸šåŠ¡å±‚         â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Vue 3         â”‚â—„â”€â”€â–ºâ”‚ â€¢ RESTful API   â”‚â—„â”€â”€â–ºâ”‚ â€¢ çˆ¬è™«æœåŠ¡       â”‚
â”‚ â€¢ Element Plus  â”‚    â”‚ â€¢ WebSocket     â”‚    â”‚ â€¢ è®¤è¯æœåŠ¡       â”‚
â”‚ â€¢ Axios         â”‚    â”‚ â€¢ è·¯ç”±ç®¡ç†        â”‚    â”‚ â€¢ ä¸‹è½½æœåŠ¡       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â–²
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ•°æ®å±‚         â”‚
â”‚                 â”‚
â”‚ â€¢ çˆ¬è™«å¼•æ“       â”‚
â”‚ â€¢ çŠ¶æ€ç®¡ç†       â”‚
â”‚ â€¢ æ–‡ä»¶å­˜å‚¨       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


## ğŸ“‚ ç›®å½•ç»“æ„è¯¦è§£

### æ ¸å¿ƒæ¨¡å—

- **`api/`** - APIæ¥å£å±‚ï¼Œå¤„ç†HTTPè¯·æ±‚å’Œå“åº”
- **`services/`** - ä¸šåŠ¡é€»è¾‘å±‚ï¼Œå°è£…æ ¸å¿ƒåŠŸèƒ½
- **`spiders/`** - çˆ¬è™«å¼•æ“å±‚ï¼Œå®ç°å„å¹³å°æ•°æ®é‡‡é›†
- **`core/`** - æ ¸å¿ƒçŠ¶æ€ç®¡ç†
- **`frontend/`** - å‰ç«¯èµ„æºå’Œæ¨¡æ¿
- **`utils/`** - é€šç”¨å·¥å…·å‡½æ•°

### æ•°æ®æµå‘

1. **ç”¨æˆ·äº¤äº’** â†’ å‰ç«¯Vueç»„ä»¶
2. **APIè¯·æ±‚** â†’ Flaskè·¯ç”±å¤„ç†
3. **ä¸šåŠ¡å¤„ç†** â†’ æœåŠ¡å±‚è°ƒç”¨
4. **æ•°æ®é‡‡é›†** â†’ çˆ¬è™«å¼•æ“æ‰§è¡Œ
5. **ç»“æœè¿”å›** â†’ WebSocketå®æ—¶æ¨é€
6. **çŠ¶æ€æ›´æ–°** â†’ å‰ç«¯ç•Œé¢åˆ·æ–°

## ğŸ”§ æŠ€æœ¯æ ˆ

### åç«¯æŠ€æœ¯
- **Flask** - è½»é‡çº§Webæ¡†æ¶
- **Flask-SocketIO** - WebSocketå®æ—¶é€šä¿¡
- **Requests** - HTTPè¯·æ±‚åº“
- **BeautifulSoup** - HTMLè§£æ
- **Pillow** - å›¾åƒå¤„ç†

### å‰ç«¯æŠ€æœ¯
- **Vue 3** - æ¸è¿›å¼JavaScriptæ¡†æ¶
- **Element Plus** - Vue 3ç»„ä»¶åº“
- **Vite** - ç°ä»£åŒ–æ„å»ºå·¥å…·
- **Socket.IO** - å®æ—¶é€šä¿¡å®¢æˆ·ç«¯
- **Axios** - HTTPå®¢æˆ·ç«¯

## ğŸš€ å¯åŠ¨æµç¨‹

1. **ç¯å¢ƒåˆå§‹åŒ–** - è™šæ‹Ÿç¯å¢ƒå’Œä¾èµ–å®‰è£…
2. **æœåŠ¡å¯åŠ¨** - Flaskåº”ç”¨å’ŒSocketIOæœåŠ¡
3. **å‰ç«¯æ„å»º** - Vueé¡¹ç›®ç¼–è¯‘å’Œé™æ€èµ„æºç”Ÿæˆ
4. **è·¯ç”±æ³¨å†Œ** - APIç«¯ç‚¹å’ŒWebSocketäº‹ä»¶ç»‘å®š
5. **çŠ¶æ€åˆå§‹åŒ–** - å…¨å±€å˜é‡å’Œä»»åŠ¡é˜Ÿåˆ—å‡†å¤‡

## ğŸ“Š æ€§èƒ½ç‰¹ç‚¹

- **å¼‚æ­¥å¤„ç†**ï¼šæ”¯æŒå¹¶å‘çˆ¬å–ä»»åŠ¡
- **æ™ºèƒ½å»¶è¿Ÿ**ï¼šéšæœºå»¶è¿Ÿé¿å…åçˆ¬æ£€æµ‹
- **é”™è¯¯æ¢å¤**ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶
- **èµ„æºä¼˜åŒ–**ï¼šåˆç†çš„å†…å­˜å’Œç½‘ç»œä½¿ç”¨

---

> ğŸ’¡ **è®¾è®¡ç†å¿µ**ï¼šæœ¬é¡¹ç›®é‡‡ç”¨ç°ä»£åŒ–çš„å¾®æœåŠ¡æ€æƒ³ï¼Œé€šè¿‡æ¸…æ™°çš„åˆ†å±‚æ¶æ„å®ç°é«˜å†…èšä½è€¦åˆï¼Œç¡®ä¿ç³»ç»Ÿçš„å¯ç»´æŠ¤æ€§å’Œå¯æ‰©å±•æ€§ã€‚

---

# ğŸ•·ï¸ çˆ¬è™«å¼•æ“æ·±åº¦è§£æ

## æ¦‚è¿°

æœ¬é¡¹ç›®çš„çˆ¬è™«å¼•æ“é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œæ¯ä¸ªçˆ¬è™«ç±»ç‹¬ç«‹å®ç°ç‰¹å®šå¹³å°çš„æ•°æ®é‡‡é›†é€»è¾‘ã€‚é€šè¿‡ç»Ÿä¸€çš„æ¥å£è§„èŒƒï¼Œå®ç°äº†å¯æ’æ‹”çš„çˆ¬è™«æ¶æ„ã€‚

## ğŸ—ï¸ çˆ¬è™«æ¶æ„è®¾è®¡

### ç»Ÿä¸€æ¥å£è§„èŒƒ

æ‰€æœ‰çˆ¬è™«ç±»éƒ½éµå¾ªç›¸åŒçš„æ¥å£è®¾è®¡ï¼š

```python
class SpiderInterface:
    def search(self, keyword: str, max_results: int = 10, **kwargs) -> List[Dict]:
        """ç»Ÿä¸€çš„æœç´¢æ¥å£"""
        pass
```

### æ ¸å¿ƒç»„ä»¶

1. **è¯·æ±‚ç®¡ç†å™¨** - å¤„ç†HTTPè¯·æ±‚å’Œå“åº”
2. **è§£æå¼•æ“** - æå–å’Œæ¸…æ´—æ•°æ®
3. **åçˆ¬ç­–ç•¥** - æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
4. **é”™è¯¯å¤„ç†** - å¼‚å¸¸æ•è·å’Œæ¢å¤

## ğŸ” ç™¾åº¦æœç´¢çˆ¬è™« (BaiduSpider)

### æŠ€æœ¯åŸç†

ç™¾åº¦æœç´¢çˆ¬è™«é€šè¿‡æ¨¡æ‹Ÿæµè§ˆå™¨è¡Œä¸ºï¼Œè§£ææœç´¢ç»“æœé¡µé¢çš„HTMLç»“æ„æ¥æå–æ•°æ®ã€‚

```python
class BaiduSpider:
    USER_AGENTS = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...',
        # å¤šä¸ªUser-Agentè½®æ¢ä½¿ç”¨
    ]
    
    def search(self, keyword: str, max_results: int = 10, search_type: str = 'web'):
        # æ„å»ºæœç´¢URL
        if search_type == 'web':
            url = f'https://www.baidu.com/s?wd={quote(keyword)}'
        elif search_type == 'image':
            url = f'https://image.baidu.com/search/index?tn=baiduimage&word={quote(keyword)}'
```

### å…³é”®æŠ€æœ¯ç‚¹

#### 1. åçˆ¬è™«ç­–ç•¥
```python
def _get_soup(self, url: str):
    # éšæœºå»¶è¿Ÿ
    time.sleep(random.uniform(*self.delay_range))
    
    # éšæœºUser-Agent
    headers = {**self.headers, 'User-Agent': random.choice(self.USER_AGENTS)}
    
    # è®¾ç½®Referer
    headers['Referer'] = 'https://www.baidu.com/'
```

#### 2. æ•°æ®è§£æ
```python
def _search_web(self, url: str, max_results: int):
    soup = self._get_soup(url)
    results = []
    
    # è§£ææœç´¢ç»“æœå®¹å™¨
    result_containers = soup.find_all('div', class_='result')
    
    for container in result_containers[:max_results]:
        # æå–æ ‡é¢˜
        title_elem = container.find('h3') or container.find('a')
        title = title_elem.get_text(strip=True) if title_elem else 'æ— æ ‡é¢˜'
        
        # æå–é“¾æ¥
        link_elem = container.find('a', href=True)
        url = link_elem['href'] if link_elem else ''
        
        # æå–æè¿°
        desc_elem = container.find('span', class_='content-right_8Zs40')
        description = desc_elem.get_text(strip=True) if desc_elem else ''
```

### æ•°æ®ç»“æ„

è¿”å›çš„æ•°æ®ç»“æ„ç»Ÿä¸€ä¸ºï¼š
```python
{
    'index': 1,
    'title': 'æœç´¢ç»“æœæ ‡é¢˜',
    'url': 'https://example.com',
    'description': 'æœç´¢ç»“æœæè¿°',
    'image_url': 'https://image.url'  # ä»…å›¾ç‰‡æœç´¢
}
```

## ğŸ“º Bç«™è§†é¢‘çˆ¬è™« (BilibiliSpider)

### æŠ€æœ¯ç‰¹ç‚¹

Bç«™çˆ¬è™«ä¸“é—¨é’ˆå¯¹è§†é¢‘å†…å®¹è¿›è¡Œä¼˜åŒ–ï¼Œèƒ½å¤Ÿæå–è§†é¢‘çš„è¯¦ç»†å…ƒæ•°æ®ã€‚

#### 1. è§†é¢‘ä¿¡æ¯æå–
```python
def _parse_video_item(self, item):
    # æå–è§†é¢‘æ ‡é¢˜
    title_elem = item.find('a', {'title': True}) or item.find('h3', {'title': True})
    title = title_elem.get('title', '').strip() if title_elem else ''
    
    # æå–è§†é¢‘é“¾æ¥
    link_elem = item.find('a', href=True)
    if link_elem:
        href = link_elem['href']
        if href.startswith('//'):
            url = 'https:' + href
        elif href.startswith('/'):
            url = 'https://www.bilibili.com' + href
    
    # æå–UPä¸»ä¿¡æ¯
    author_elem = item.find('a', class_='up-name') or item.find('span', class_='up-name')
    author = author_elem.get_text(strip=True) if author_elem else 'æœªçŸ¥UPä¸»'
    
    # æå–æ’­æ”¾é‡
    play_elem = item.find('span', class_='so-icon watch-num')
    play_count = play_elem.get_text(strip=True) if play_elem else '0'
```

#### 2. åçˆ¬æ£€æµ‹å¤„ç†
```python
def _get_soup(self, url: str):
    response = requests.get(url, headers=self.headers, timeout=10)
    
    # æ£€æµ‹åçˆ¬æœºåˆ¶
    if len(response.text) < 5000 or "éªŒè¯" in response.text:
        print("âš ï¸ å¯èƒ½è§¦å‘äº†åçˆ¬æœºåˆ¶")
        return None
```

## ğŸ“ CSDNæ–‡ç« çˆ¬è™« (CSDNSpider)

### APIæ¥å£è°ƒç”¨

CSDNçˆ¬è™«é‡‡ç”¨APIæ¥å£æ–¹å¼ï¼Œç›´æ¥è·å–JSONæ•°æ®ï¼Œé¿å…äº†HTMLè§£æçš„å¤æ‚æ€§ã€‚

```python
def search(self, keyword: str, max_results: int = 10):
    # æ„å»ºAPIè¯·æ±‚URL
    url = f'https://so.csdn.net/api/v3/search?q={quote(keyword)}&t=all&p=1&s=0&tm=0&lv=-1&ft=0&l=&u=&ct=-1&pnt=-1&ry=-1&ss=-1&dct=-1&vco=-1'
    
    json_data = self._get_json(url)
    if not json_data or 'result_vos' not in json_data:
        return []
```

### æ•°æ®æ¸…æ´—
```python
def _clean_html_tags(self, text: str):
    """æ¸…é™¤HTMLæ ‡ç­¾"""
    if not text:
        return text
    return re.sub(r'<[^>]+>', '', text)

def _parse_article(self, article: dict):
    return {
        'index': len(results) + 1,
        'title': self._clean_html_tags(article.get('title', '')),
        'url': article.get('url', ''),
        'description': self._clean_html_tags(article.get('description', '')),
        'author': article.get('nickname', ''),
        'publish_time': article.get('create_time', '')
    }
```

## ğŸŒ URLå†…å®¹æå–å™¨ (WebContentExtractor)

### æ™ºèƒ½å†…å®¹è¯†åˆ«

URLæå–å™¨æ˜¯æœ€å¤æ‚çš„ç»„ä»¶ï¼Œéœ€è¦å¤„ç†å„ç§ç±»å‹çš„ç½‘é¡µå†…å®¹ã€‚

#### 1. ç»“æ„åŒ–å†…å®¹æå–
```python
def get_web_content(self, url: str):
    resp = requests.get(url, headers=self.headers, timeout=15)
    resp.encoding = resp.apparent_encoding or resp.encoding or 'utf-8'
    
    html_content = resp.text
    
    # æå–ç»“æ„åŒ–ä¿¡æ¯
    title = self.extract_page_title(html_content)
    text_content = self.extract_text_content(html_content)
    images = self.extract_images(html_content, url)
    
    # æ„å»ºç»“æ„åŒ–å†…å®¹
    structured_content = {
        'title': title,
        'url': url,
        'text_length': len(text_content),
        'images_count': len(images),
        'preview': text_content[:500] + '...' if len(text_content) > 500 else text_content,
        'full_content': text_content,
        'images': images[:10],
        'metadata': {
            'content_type': resp.headers.get('content-type', ''),
            'status_code': resp.status_code,
            'final_url': resp.url,
            'charset': resp.encoding or 'utf-8'
        }
    }
```

#### 2. æ–‡æœ¬å†…å®¹æå–
```python
def extract_text_content(self, html: str) -> str:
    # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
    html = re.sub(r'<script[^>]*>.*?</script>', '', html, flags=re.DOTALL | re.IGNORECASE)
    html = re.sub(r'<style[^>]*>.*?</style>', '', html, flags=re.DOTALL | re.IGNORECASE)
    
    # ç§»é™¤HTMLæ ‡ç­¾
    text = re.sub(r'<[^>]+>', '', html)
    
    # æ¸…ç†ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text
```

#### 3. å›¾ç‰‡é“¾æ¥æå–
```python
def extract_images(self, html: str, base_url: str) -> list:
    img_pattern = r'<img[^>]+src=["\']([^"\'>]+)["\'][^>]*>'
    img_matches = re.findall(img_pattern, html, re.IGNORECASE)
    
    images = []
    for img_url in img_matches:
        # å¤„ç†ç›¸å¯¹URL
        full_url = urljoin(base_url, img_url)
        
        # éªŒè¯å›¾ç‰‡URL
        if self._is_valid_image_url(full_url):
            images.append(full_url)
    
    return list(set(images))  # å»é‡
```

## ğŸ›¡ï¸ åçˆ¬è™«ç­–ç•¥

### 1. è¯·æ±‚å¤´ä¼ªè£…
- éšæœºUser-Agentè½®æ¢
- è®¾ç½®åˆç†çš„Referer
- æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¯·æ±‚å¤´

### 2. è®¿é—®é¢‘ç‡æ§åˆ¶
- éšæœºå»¶è¿Ÿæœºåˆ¶
- è¯·æ±‚é—´éš”æ§åˆ¶
- å¹¶å‘æ•°é‡é™åˆ¶

### 3. é”™è¯¯å¤„ç†
- ç½‘ç»œè¶…æ—¶é‡è¯•
- HTTPçŠ¶æ€ç æ£€æŸ¥
- åçˆ¬æ£€æµ‹è¯†åˆ«

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. å†…å­˜ç®¡ç†
- åŠæ—¶é‡Šæ”¾å¤§å¯¹è±¡
- é™åˆ¶ç»“æœæ•°é‡
- æµå¼å¤„ç†å¤§æ–‡ä»¶

### 2. ç½‘ç»œä¼˜åŒ–
- è¿æ¥æ± å¤ç”¨
- å‹ç¼©ä¼ è¾“
- è¶…æ—¶æ§åˆ¶

### 3. ç¼“å­˜ç­–ç•¥
- ç»“æœç¼“å­˜
- è¯·æ±‚å»é‡
- æ™ºèƒ½æ›´æ–°

---

> ğŸ”§ **æŠ€æœ¯è¦ç‚¹**ï¼šçˆ¬è™«å¼•æ“çš„æ ¸å¿ƒåœ¨äºå¹³è¡¡æ•ˆç‡ä¸ç¨³å®šæ€§ï¼Œé€šè¿‡åˆç†çš„åçˆ¬ç­–ç•¥å’Œé”™è¯¯å¤„ç†æœºåˆ¶ï¼Œç¡®ä¿é•¿æœŸç¨³å®šè¿è¡Œã€‚

---

# ğŸŒ å‰åç«¯æ¶æ„è¯¦è§£

## æ¶æ„æ¦‚è¿°

æœ¬é¡¹ç›®é‡‡ç”¨ç°ä»£åŒ–çš„å‰åç«¯åˆ†ç¦»æ¶æ„ï¼Œé€šè¿‡RESTful APIå’ŒWebSocketå®ç°æ•°æ®äº¤äº’ï¼Œæä¾›äº†è‰¯å¥½çš„ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿå¯ç»´æŠ¤æ€§ã€‚

## ğŸ”§ åç«¯æ¶æ„ (Flask)

### åº”ç”¨å·¥å‚æ¨¡å¼

```python
# src/app.py
def create_app():
    app = Flask(__name__)
    
    # é…ç½®CORS
    CORS(app, resources={r"/api/*": {"origins": "*"}})
    
    # åˆå§‹åŒ–SocketIO
    socketio.init_app(app, cors_allowed_origins="*")
    
    # æ³¨å†Œè“å›¾
    from src.api.crawl import api_bp
    from src.api.bilibili import bili_bp
    from src.api.stats import stats_bp
    
    app.register_blueprint(api_bp)
    app.register_blueprint(bili_bp)
    app.register_blueprint(stats_bp)
    
    return app
```

### è“å›¾æ¨¡å—åŒ–è®¾è®¡

#### 1. çˆ¬è™«APIè“å›¾ (`api/crawl.py`)

**æ ¸å¿ƒæ¥å£**ï¼š
- `GET /api/spiders` - è·å–å¯ç”¨çˆ¬è™«åˆ—è¡¨
- `POST /api/crawl` - æ‰§è¡Œçˆ¬å–ä»»åŠ¡
- `GET /api/task/{task_id}` - æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€

**è¯·æ±‚å¤„ç†æµç¨‹**ï¼š
```python
@api_bp.route('/api/crawl', methods=['POST'])
def crawl():
    # 1. å‚æ•°éªŒè¯
    data = request.get_json() or {}
    spider_type = data.get('spider_type')
    if not spider_type:
        return jsonify({'success': False, 'message': 'ç¼ºå°‘çˆ¬è™«ç±»å‹'}), 400
    
    # 2. ä»»åŠ¡åˆ›å»º
    task_counter += 1
    task = {
        'id': task_counter,
        'spider_type': spider_type,
        'status': 'running',
        'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    # 3. çˆ¬è™«æ‰§è¡Œ
    if task_type == 'search':
        search_results, error = crawler_service.execute_search(
            spider_type, keyword, max_results, data_type
        )
    elif task_type == 'url':
        content_data, error = crawler_service.extract_url_content(url)
    
    # 4. ç»“æœè¿”å›
    return jsonify({
        'success': True, 
        'message': 'çˆ¬å–ä»»åŠ¡å®Œæˆ', 
        'task_id': task_counter, 
        'results': result['data']
    })
```

#### 2. Bç«™åŠŸèƒ½è“å›¾ (`api/bilibili.py`)

**è®¤è¯ç›¸å…³**ï¼š
- `GET /api/bilibili/login/qr` - è·å–ç™»å½•äºŒç»´ç 
- `POST /api/bilibili/login/poll` - è½®è¯¢ç™»å½•çŠ¶æ€
- `GET /api/bilibili/login/status` - æ£€æŸ¥ç™»å½•çŠ¶æ€
- `POST /api/bilibili/logout` - ç”¨æˆ·ç™»å‡º

**è§†é¢‘åŠŸèƒ½**ï¼š
- `POST /api/bilibili/video/info` - è·å–è§†é¢‘ä¿¡æ¯
- `POST /api/bilibili/video/download` - ä¸‹è½½è§†é¢‘
- `GET /api/bilibili/video/download/status/{task_id}` - æŸ¥è¯¢ä¸‹è½½çŠ¶æ€

**äºŒç»´ç ç™»å½•å®ç°**ï¼š
```python
@bili_bp.get('/api/bilibili/login/qr')
def get_bilibili_qr():
    ok, msg, data = auth.get_qr()
    if not ok:
        return jsonify({'success': False, 'message': msg})
    return jsonify({'success': True, **data})

# è®¤è¯æœåŠ¡å®ç°
def get_qr():
    # 1. è·å–äºŒç»´ç æ•°æ®
    resp = login_session.get(
        'https://passport.bilibili.com/x/passport-login/web/qrcode/generate?source=main-fe-header'
    ).json()
    
    # 2. ç”ŸæˆäºŒç»´ç å›¾ç‰‡
    login_url = resp['data']['url']
    qr = qrcode.QRCode(version=1, box_size=10, border=5)
    qr.add_data(login_url)
    qr.make(fit=True)
    img = qr.make_image(fill_color="black", back_color="white")
    
    # 3. è½¬æ¢ä¸ºBase64
    buffer = io.BytesIO()
    img.save(buffer, format='PNG')
    img_str = base64.b64encode(buffer.getvalue()).decode()
    qr_data_url = f"data:image/png;base64,{img_str}"
    
    return True, "", {
        'qr_url': qr_data_url,
        'login_url': login_url,
        'qrcode_key': resp['data']['qrcode_key']
    }
```

### æœåŠ¡å±‚è®¾è®¡

#### çˆ¬è™«æœåŠ¡ (`services/crawler_service.py`)

```python
class CrawlerService:
    def __init__(self):
        self.spiders = {
            'baidu': {'name': 'ç™¾åº¦æœç´¢', 'class': BaiduSpider, 'type': 'search'},
            'bilibili': {'name': 'å“”å“©å“”å“©', 'class': BilibiliSpider, 'type': 'search'},
            'csdn': {'name': 'CSDN', 'class': CSDNSpider, 'type': 'search'},
            'url': {'name': 'è‡ªå®šä¹‰URL', 'class': WebContentExtractor, 'type': 'url'}
        }
    
    def execute_search(self, spider_type: str, keyword: str, max_results: int, data_type: str):
        """æ‰§è¡Œæœç´¢ä»»åŠ¡"""
        if spider_type not in self.spiders:
            return None, f"ä¸æ”¯æŒçš„çˆ¬è™«ç±»å‹: {spider_type}"
        
        spider_class = self.spiders[spider_type]['class']
        spider = spider_class()
        
        try:
            if spider_type == 'baidu':
                results = spider.search(keyword, max_results, data_type)
            else:
                results = spider.search(keyword, max_results)
            
            return results, None
        except Exception as e:
            return None, str(e)
```

### WebSocketå®æ—¶é€šä¿¡

```python
# src/extensions.py
from flask_socketio import SocketIO
socketio = SocketIO(cors_allowed_origins="*")

# ä¸‹è½½è¿›åº¦æ¨é€
def emit_download_progress(task_id, progress_data):
    socketio.emit('download_progress', {
        'task_id': task_id,
        'progress': progress_data['progress'],
        'speed': progress_data['speed'],
        'eta': progress_data['eta']
    })
```

## ğŸ¨ å‰ç«¯æ¶æ„ (Vue 3)

### é¡¹ç›®ç»“æ„
frontend/vue/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/          # å¯å¤ç”¨ç»„ä»¶
â”‚   â”œâ”€â”€ views/              # é¡µé¢ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ Crawler.vue     # çˆ¬è™«ä¸»ç•Œé¢
â”‚   â”‚   â”œâ”€â”€ Docs.vue        # æ–‡æ¡£é¡µé¢
â”‚   â”‚   â””â”€â”€ About.vue       # å…³äºé¡µé¢
â”‚   â”œâ”€â”€ router/             # è·¯ç”±é…ç½®
â”‚   â”œâ”€â”€ style/              # æ ·å¼æ–‡ä»¶
â”‚   â”œâ”€â”€ App.vue             # æ ¹ç»„ä»¶
â”‚   â””â”€â”€ main.js             # å…¥å£æ–‡ä»¶
â”œâ”€â”€ public/                 # é™æ€èµ„æº
â””â”€â”€ package.json            # ä¾èµ–é…ç½®


### ä¸»åº”ç”¨å…¥å£

```javascript
// src/main.js
import { createApp } from 'vue'
import App from './App.vue'
import router from './router'
import ElementPlus from 'element-plus'
import 'element-plus/dist/index.css'
import * as ElementPlusIconsVue from '@element-plus/icons-vue'

const app = createApp(App)

// æ³¨å†ŒElement Pluså›¾æ ‡
for (const [key, component] of Object.entries(ElementPlusIconsVue)) {
  app.component(key, component)
}

app.use(router)
app.use(ElementPlus)
app.mount('#app')
```

### æ ¸å¿ƒç»„ä»¶è®¾è®¡

#### çˆ¬è™«ä¸»ç•Œé¢ (`views/Crawler.vue`)

**ç»„ä»¶ç»“æ„**ï¼š
```vue
<template>
  <div class="crawler-container">
    <!-- çˆ¬è™«ç±»å‹é€‰æ‹© -->
    <el-card class="spider-selector">
      <el-radio-group v-model="selectedSpider">
        <el-radio-button 
          v-for="spider in spiders" 
          :key="spider.id" 
          :label="spider.id"
        >
          {{ spider.icon }} {{ spider.name }}
        </el-radio-button>
      </el-radio-group>
    </el-card>
    
    <!-- å‚æ•°é…ç½® -->
    <el-card class="params-config">
      <el-form :model="currentParams" label-width="120px">
        <el-form-item label="æœç´¢å…³é”®è¯" v-if="isSearchType">
          <el-input v-model="currentParams.keyword" placeholder="è¯·è¾“å…¥æœç´¢å…³é”®è¯" />
        </el-form-item>
        <el-form-item label="ç›®æ ‡URL" v-if="isUrlType">
          <el-input v-model="currentParams.url" placeholder="è¯·è¾“å…¥è¦çˆ¬å–çš„URL" />
        </el-form-item>
        <el-form-item label="ç»“æœæ•°é‡">
          <el-input-number v-model="currentParams.max_results" :min="1" :max="100" />
        </el-form-item>
      </el-form>
    </el-card>
    
    <!-- æ‰§è¡ŒæŒ‰é’® -->
    <el-button 
      type="primary" 
      size="large" 
      :loading="isExecuting" 
      :disabled="!canExecute"
      @click="executeCrawl"
    >
      {{ isExecuting ? 'çˆ¬å–ä¸­...' : 'å¼€å§‹çˆ¬å–' }}
    </el-button>
    
    <!-- ç»“æœå±•ç¤º -->
    <el-card class="results-display" v-if="results.length > 0">
      <template #header>
        <div class="results-header">
          <span>çˆ¬å–ç»“æœ ({{ results.length }}æ¡)</span>
          <el-button type="success" @click="exportResults">å¯¼å‡ºç»“æœ</el-button>
        </div>
      </template>
      
      <div class="results-list">
        <div 
          v-for="(result, index) in paginatedResults" 
          :key="index" 
          class="result-item"
        >
          <h4>{{ result.title }}</h4>
          <p class="result-url">{{ result.url }}</p>
          <p class="result-description">{{ result.description }}</p>
          <div class="result-actions">
            <el-button size="small" @click="toggleResultDetail(index)">æŸ¥çœ‹è¯¦æƒ…</el-button>
          </div>
        </div>
      </div>
      
      <!-- åˆ†é¡µ -->
      <el-pagination
        v-model:current-page="currentPage"
        :page-size="pageSize"
        :total="results.length"
        layout="prev, pager, next, jumper"
        @current-change="handlePageChange"
      />
    </el-card>
  </div>
</template>
```

**å“åº”å¼æ•°æ®ç®¡ç†**ï¼š
```javascript
<script setup>
import { ref, computed, watch, onMounted } from 'vue'
import axios from 'axios'
import { io } from 'socket.io-client'

// å“åº”å¼æ•°æ®
const selectedSpider = ref('baidu')
const isExecuting = ref(false)
const results = ref([])
const spiders = ref([])
const currentPage = ref(1)
const pageSize = ref(10)

// çˆ¬è™«å‚æ•°
const baiduParams = ref({ keyword: '', max_results: 20, data_type: 'web' })
const bilibiliParams = ref({ keyword: '', max_results: 20 })
const csdnParams = ref({ keyword: '', max_results: 20 })
const urlParams = ref({ url: '' })

// è®¡ç®—å±æ€§
const canExecute = computed(() => {
  if (isExecuting.value) return false
  
  const spider = spiders.value.find(s => s.id === selectedSpider.value)
  if (!spider) return false
  
  if (spider.type === 'search') {
    return currentKeyword.value.trim().length > 0
  } else if (spider.type === 'url') {
    return urlParams.value.url.trim().length > 0
  }
  
  return false
})

const currentKeyword = computed(() => {
  switch (selectedSpider.value) {
    case 'baidu': return baiduParams.value.keyword
    case 'bilibili': return bilibiliParams.value.keyword
    case 'csdn': return csdnParams.value.keyword
    default: return ''
  }
})

const paginatedResults = computed(() => {
  const start = (currentPage.value - 1) * pageSize.value
  const end = start + pageSize.value
  return results.value.slice(start, end)
})

// æ–¹æ³•
const executeCrawl = async () => {
  isExecuting.value = true
  results.value = []
  
  try {
    const spider = spiders.value.find(s => s.id === selectedSpider.value)
    let requestData = { spider_type: selectedSpider.value }
    
    if (spider.type === 'search') {
      requestData.keyword = currentKeyword.value
      requestData.max_results = getCurrentParams().max_results
      if (selectedSpider.value === 'baidu') {
        requestData.data_type = baiduParams.value.data_type
      }
    } else if (spider.type === 'url') {
      requestData.url = urlParams.value.url
    }
    
    const response = await axios.post('/api/crawl', requestData)
    
    if (response.data.success) {
      results.value = response.data.results || []
      ElMessage.success(`çˆ¬å–å®Œæˆï¼Œè·å¾— ${results.value.length} æ¡ç»“æœ`)
    } else {
      ElMessage.error(response.data.message || 'çˆ¬å–å¤±è´¥')
    }
  } catch (error) {
    console.error('çˆ¬å–é”™è¯¯:', error)
    ElMessage.error('ç½‘ç»œé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•')
  } finally {
    isExecuting.value = false
  }
}

const loadSpiders = async () => {
  try {
    const response = await axios.get('/api/spiders')
    spiders.value = response.data
  } catch (error) {
    console.error('åŠ è½½çˆ¬è™«åˆ—è¡¨å¤±è´¥:', error)
  }
}

// ç”Ÿå‘½å‘¨æœŸ
onMounted(() => {
  loadSpiders()
})
</script>
```

### Socket.IOå®æ—¶é€šä¿¡

```javascript
// WebSocketè¿æ¥ç®¡ç†
const socket = ref(null)
const downloadTasks = ref([])

const initSocket = () => {
  socket.value = io()
  
  // ç›‘å¬ä¸‹è½½è¿›åº¦
  socket.value.on('download_progress', (data) => {
    const task = downloadTasks.value.find(t => t.id === data.task_id)
    if (task) {
      task.progress = data.progress
      task.speed = data.speed
      task.eta = data.eta
    }
  })
  
  // ç›‘å¬ä¸‹è½½å®Œæˆ
  socket.value.on('download_complete', (data) => {
    const task = downloadTasks.value.find(t => t.id === data.task_id)
    if (task) {
      task.status = 'completed'
      task.file_path = data.file_path
      ElMessage.success(`ä¸‹è½½å®Œæˆ: ${task.title}`)
    }
  })
  
  // ç›‘å¬ä¸‹è½½é”™è¯¯
  socket.value.on('download_error', (data) => {
    const task = downloadTasks.value.find(t => t.id === data.task_id)
    if (task) {
      task.status = 'error'
      task.error = data.error
      ElMessage.error(`ä¸‹è½½å¤±è´¥: ${data.error}`)
    }
  })
}

const disconnectSocket = () => {
  if (socket.value) {
    socket.value.disconnect()
    socket.value = null
  }
}
```

## ğŸ”„ æ•°æ®æµè½¬æœºåˆ¶

### è¯·æ±‚-å“åº”æµç¨‹

1. **ç”¨æˆ·æ“ä½œ** â†’ å‰ç«¯Vueç»„ä»¶è§¦å‘äº‹ä»¶
2. **å‚æ•°éªŒè¯** â†’ å‰ç«¯éªŒè¯è¾“å…¥å‚æ•°æœ‰æ•ˆæ€§
3. **APIè¯·æ±‚** â†’ Axioså‘é€HTTPè¯·æ±‚åˆ°Flaskåç«¯
4. **è·¯ç”±åˆ†å‘** â†’ Flaskæ ¹æ®URLè·¯ç”±åˆ°å¯¹åº”çš„è“å›¾å¤„ç†å‡½æ•°
5. **ä¸šåŠ¡å¤„ç†** â†’ æœåŠ¡å±‚è°ƒç”¨çˆ¬è™«å¼•æ“æ‰§è¡Œä»»åŠ¡
6. **æ•°æ®è¿”å›** â†’ JSONæ ¼å¼å“åº”è¿”å›ç»™å‰ç«¯
7. **ç•Œé¢æ›´æ–°** â†’ Vueå“åº”å¼ç³»ç»Ÿæ›´æ–°ç•Œé¢æ˜¾ç¤º

### WebSocketå®æ—¶é€šä¿¡æµç¨‹

1. **è¿æ¥å»ºç«‹** â†’ å‰ç«¯å»ºç«‹Socket.IOè¿æ¥
2. **ä»»åŠ¡å¯åŠ¨** â†’ åç«¯å¯åŠ¨å¼‚æ­¥ä¸‹è½½ä»»åŠ¡
3. **è¿›åº¦æ¨é€** â†’ åç«¯å®šæœŸæ¨é€ä»»åŠ¡è¿›åº¦
4. **å‰ç«¯æ›´æ–°** â†’ å‰ç«¯å®æ—¶æ›´æ–°è¿›åº¦æ¡å’ŒçŠ¶æ€
5. **ä»»åŠ¡å®Œæˆ** â†’ åç«¯æ¨é€å®Œæˆé€šçŸ¥
6. **ç»“æœå±•ç¤º** â†’ å‰ç«¯æ˜¾ç¤ºæœ€ç»ˆç»“æœ

## ğŸ›¡ï¸ å®‰å…¨æ€§è®¾è®¡

### CORSé…ç½®
```python
CORS(app, resources={r"/api/*": {"origins": "*"}})
```

### è¾“å…¥éªŒè¯
```python
def crawl():
    data = request.get_json() or {}
    spider_type = data.get('spider_type')
    if not spider_type:
        return jsonify({'success': False, 'message': 'ç¼ºå°‘çˆ¬è™«ç±»å‹'}), 400
```

### é”™è¯¯å¤„ç†
```javascript
try {
  const response = await axios.post('/api/crawl', requestData)
  // å¤„ç†æˆåŠŸå“åº”
} catch (error) {
  console.error('çˆ¬å–é”™è¯¯:', error)
  ElMessage.error('ç½‘ç»œé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•')
}
```

---

> ğŸš€ **æ¶æ„ä¼˜åŠ¿**ï¼šå‰åç«¯åˆ†ç¦»æ¶æ„æä¾›äº†è‰¯å¥½çš„å¯ç»´æŠ¤æ€§å’Œæ‰©å±•æ€§ï¼ŒWebSocketå®æ—¶é€šä¿¡å¢å¼ºäº†ç”¨æˆ·ä½“éªŒï¼Œæ¨¡å—åŒ–è®¾è®¡ä¾¿äºåŠŸèƒ½æ‰©å±•å’Œç»´æŠ¤ã€‚

---

# âš™ï¸ æ ¸å¿ƒåŠŸèƒ½å®ç°è¯¦è§£

## æ¦‚è¿°

æœ¬æ–‡æ¡£æ·±å…¥è§£æNYLGçˆ¬è™«ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½å®ç°ï¼ŒåŒ…æ‹¬Bç«™è®¤è¯ç³»ç»Ÿã€è§†é¢‘ä¸‹è½½åŠŸèƒ½ã€çŠ¶æ€ç®¡ç†æœºåˆ¶ç­‰å…³é”®æŠ€æœ¯ç‚¹ã€‚

## ğŸ” Bç«™è®¤è¯ç³»ç»Ÿ

### äºŒç»´ç ç™»å½•æœºåˆ¶

Bç«™é‡‡ç”¨äºŒç»´ç æ‰«ç ç™»å½•æ–¹å¼ï¼Œæ•´ä¸ªæµç¨‹åŒ…æ‹¬ï¼šäºŒç»´ç ç”Ÿæˆ â†’ ç”¨æˆ·æ‰«ç  â†’ çŠ¶æ€è½®è¯¢ â†’ è·å–Cookie

#### 1. äºŒç»´ç ç”Ÿæˆ

```python
# src/services/bilibili_auth.py
def get_qr():
    global login_session
    try:
        login_session = requests.session()
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...'
        }
        
        # è¯·æ±‚Bç«™äºŒç»´ç æ¥å£
        resp = login_session.get(
            'https://passport.bilibili.com/x/passport-login/web/qrcode/generate?source=main-fe-header',
            headers=headers
        ).json()
        
        if resp['code'] != 0:
            return False, "è·å–äºŒç»´ç å¤±è´¥", None
        
        # ç”ŸæˆäºŒç»´ç å›¾ç‰‡
        login_url = resp['data']['url']
        qr = qrcode.QRCode(version=1, box_size=10, border=5)
        qr.add_data(login_url)
        qr.make(fit=True)
        img = qr.make_image(fill_color="black", back_color="white")
        img = img.resize((200, 200), Image.LANCZOS)
        
        # è½¬æ¢ä¸ºBase64ç¼–ç 
        buffer = io.BytesIO()
        img.save(buffer, format='PNG')
        img_str = base64.b64encode(buffer.getvalue()).decode()
        qr_data_url = f"data:image/png;base64,{img_str}"
        
        return True, "", {
            'qr_url': qr_data_url,
            'login_url': login_url,
            'qrcode_key': resp['data']['qrcode_key']
        }
    except Exception as e:
        return False, f'è·å–äºŒç»´ç å¤±è´¥: {str(e)}', None
```

**æŠ€æœ¯è¦ç‚¹**ï¼š
- ä½¿ç”¨`qrcode`åº“ç”ŸæˆäºŒç»´ç å›¾ç‰‡
- é€šè¿‡`PIL`è°ƒæ•´å›¾ç‰‡å°ºå¯¸
- Base64ç¼–ç ä¾¿äºå‰ç«¯æ˜¾ç¤º
- Sessionä¿æŒç™»å½•çŠ¶æ€

#### 2. ç™»å½•çŠ¶æ€è½®è¯¢

```python
def poll(qrcode_key: str):
    global global_cookies, global_bili_jct, login_session
    try:
        if not qrcode_key or not login_session:
            return False, 'å‚æ•°é”™è¯¯', None
        
        # è½®è¯¢ç™»å½•çŠ¶æ€
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...'
        }
        
        resp = login_session.get(
            f'https://passport.bilibili.com/x/passport-login/web/qrcode/poll?qrcode_key={qrcode_key}',
            headers=headers
        ).json()
        
        if resp['code'] != 0:
            return False, resp.get('message', 'è½®è¯¢å¤±è´¥'), None
        
        data = resp['data']
        
        # å¤„ç†ä¸åŒçš„ç™»å½•çŠ¶æ€
        if data['code'] == 86101:  # æœªæ‰«ç 
            return False, 'è¯·æ‰«æäºŒç»´ç ', {'status': 'waiting'}
        elif data['code'] == 86090:  # å·²æ‰«ç æœªç¡®è®¤
            return False, 'è¯·åœ¨æ‰‹æœºä¸Šç¡®è®¤ç™»å½•', {'status': 'scanned'}
        elif data['code'] == 0:  # ç™»å½•æˆåŠŸ
            # æå–Cookieå’Œcsrf token
            url = data['url']
            cookie_match = re.search(r'bili_jct=([^&]+)', url)
            if cookie_match:
                global_bili_jct = cookie_match.group(1)
            
            # ä¿å­˜å®Œæ•´Cookie
            cookies = login_session.cookies
            global_cookies = '; '.join([f'{c.name}={c.value}' for c in cookies])
            
            return True, 'ç™»å½•æˆåŠŸ', {
                'status': 'success',
                'cookies': global_cookies,
                'bili_jct': global_bili_jct
            }
        else:
            return False, f'ç™»å½•å¤±è´¥: {data.get("message", "æœªçŸ¥é”™è¯¯")}', None
            
    except Exception as e:
        return False, f'è½®è¯¢å¤±è´¥: {str(e)}', None
```

**çŠ¶æ€ç è¯´æ˜**ï¼š
- `86101`: æœªæ‰«ç çŠ¶æ€
- `86090`: å·²æ‰«ç å¾…ç¡®è®¤
- `0`: ç™»å½•æˆåŠŸ
- å…¶ä»–: ç™»å½•å¤±è´¥æˆ–è¿‡æœŸ

### Cookieç®¡ç†

```python
# å…¨å±€å˜é‡å­˜å‚¨è®¤è¯ä¿¡æ¯
global_cookies = ""
global_bili_jct = ""
login_session = None

def status():
    """æ£€æŸ¥ç™»å½•çŠ¶æ€"""
    global global_cookies, global_bili_jct
    try:
        if global_cookies and global_bili_jct:
            return True, 'å·²ç™»å½•', {
                'logged_in': True,
                'cookies': global_cookies,
                'bili_jct': global_bili_jct
            }
        else:
            return True, 'æœªç™»å½•', {'logged_in': False}
    except Exception as e:
        return False, f'çŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}', None

def logout():
    """ç”¨æˆ·ç™»å‡º"""
    global global_cookies, global_bili_jct, login_session
    try:
        global_cookies = ""
        global_bili_jct = ""
        login_session = None
        return True, 'å·²ç™»å‡º'
    except Exception as e:
        return False, f'æ³¨é”€å¤±è´¥: {str(e)}'
```

## ğŸ“¹ è§†é¢‘ä¸‹è½½ç³»ç»Ÿ

### è§†é¢‘ä¿¡æ¯è·å–

```python
# src/services/bilibili_download.py
def get_video_info(bvid: str, cookies: str = ""):
    """è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...',
            'Referer': 'https://www.bilibili.com/',
            'Cookie': cookies
        }
        
        # è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
        info_url = f'https://api.bilibili.com/x/web-interface/view?bvid={bvid}'
        resp = requests.get(info_url, headers=headers)
        data = resp.json()
        
        if data['code'] != 0:
            return None, f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}"
        
        video_data = data['data']
        
        # è·å–è§†é¢‘æµä¿¡æ¯
        cid = video_data['cid']
        stream_url = f'https://api.bilibili.com/x/player/playurl?bvid={bvid}&cid={cid}&qn=80&fnval=16'
        stream_resp = requests.get(stream_url, headers=headers)
        stream_data = stream_resp.json()
        
        if stream_data['code'] != 0:
            return None, f"è·å–è§†é¢‘æµå¤±è´¥: {stream_data.get('message', 'æœªçŸ¥é”™è¯¯')}"
        
        # è§£æè§†é¢‘æµä¿¡æ¯
        dash = stream_data['data']['dash']
        video_streams = dash.get('video', [])
        audio_streams = dash.get('audio', [])
        
        # æ„å»ºè¿”å›æ•°æ®
        video_info = {
            'bvid': bvid,
            'title': video_data['title'],
            'desc': video_data['desc'],
            'duration': video_data['duration'],
            'owner': video_data['owner']['name'],
            'view': video_data['stat']['view'],
            'danmaku': video_data['stat']['danmaku'],
            'reply': video_data['stat']['reply'],
            'favorite': video_data['stat']['favorite'],
            'coin': video_data['stat']['coin'],
            'share': video_data['stat']['share'],
            'like': video_data['stat']['like'],
            'pic': video_data['pic'],
            'video_streams': [],
            'audio_streams': []
        }
        
        # å¤„ç†è§†é¢‘æµ
        for stream in video_streams:
            video_info['video_streams'].append({
                'quality': stream['id'],
                'quality_desc': get_quality_desc(stream['id']),
                'url': stream['baseUrl'],
                'size': get_stream_file_size(stream['baseUrl'], headers),
                'codecs': stream['codecs']
            })
        
        # å¤„ç†éŸ³é¢‘æµ
        for stream in audio_streams:
            video_info['audio_streams'].append({
                'quality': stream['id'],
                'url': stream['baseUrl'],
                'size': get_stream_file_size(stream['baseUrl'], headers),
                'codecs': stream['codecs']
            })
        
        return video_info, None
        
    except Exception as e:
        return None, f"è·å–è§†é¢‘ä¿¡æ¯å¼‚å¸¸: {str(e)}"
```

### å¼‚æ­¥ä¸‹è½½å®ç°

```python
def download_video_async(task_id: str, video_url: str, audio_url: str, 
                         output_path: str, filename: str, headers: dict):
    """å¼‚æ­¥ä¸‹è½½è§†é¢‘å’ŒéŸ³é¢‘"""
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        if task_id in download_tasks:
            download_tasks[task_id]['status'] = 'downloading'
            download_tasks[task_id]['progress'] = 0
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_path, exist_ok=True)
        
        video_path = os.path.join(output_path, f"{filename}_video.mp4")
        audio_path = os.path.join(output_path, f"{filename}_audio.mp4")
        final_path = os.path.join(output_path, f"{filename}.mp4")
        
        # ä¸‹è½½è§†é¢‘æµ
        success = download_stream_with_progress(
            video_url, video_path, headers, task_id, 'video'
        )
        if not success:
            raise Exception("è§†é¢‘ä¸‹è½½å¤±è´¥")
        
        # ä¸‹è½½éŸ³é¢‘æµ
        success = download_stream_with_progress(
            audio_url, audio_path, headers, task_id, 'audio'
        )
        if not success:
            raise Exception("éŸ³é¢‘ä¸‹è½½å¤±è´¥")
        
        # åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘
        merge_success = merge_video_audio(video_path, audio_path, final_path)
        if not merge_success:
            raise Exception("è§†é¢‘åˆå¹¶å¤±è´¥")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(video_path)
            os.remove(audio_path)
        except:
            pass
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        if task_id in download_tasks:
            download_tasks[task_id]['status'] = 'completed'
            download_tasks[task_id]['progress'] = 100
            download_tasks[task_id]['file_path'] = final_path
        
        # å‘é€å®Œæˆé€šçŸ¥
        socketio.emit('download_complete', {
            'task_id': task_id,
            'file_path': final_path
        })
        
    except Exception as e:
        # æ›´æ–°é”™è¯¯çŠ¶æ€
        if task_id in download_tasks:
            download_tasks[task_id]['status'] = 'error'
            download_tasks[task_id]['error'] = str(e)
        
        # å‘é€é”™è¯¯é€šçŸ¥
        socketio.emit('download_error', {
            'task_id': task_id,
            'error': str(e)
        })

def download_stream_with_progress(url: str, output_path: str, headers: dict, 
                                 task_id: str, stream_type: str):
    """å¸¦è¿›åº¦çš„æµä¸‹è½½"""
    try:
        response = requests.get(url, headers=headers, stream=True)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        downloaded_size = 0
        
        with open(output_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded_size += len(chunk)
                    
                    # è®¡ç®—è¿›åº¦
                    if total_size > 0:
                        progress = (downloaded_size / total_size) * 100
                        
                        # å‘é€è¿›åº¦æ›´æ–°
                        socketio.emit('download_progress', {
                            'task_id': task_id,
                            'stream_type': stream_type,
                            'progress': progress,
                            'downloaded': format_file_size(downloaded_size),
                            'total': format_file_size(total_size)
                        })
        
        return True
        
    except Exception as e:
        print(f"ä¸‹è½½{stream_type}å¤±è´¥: {e}")
        return False
```

### è§†é¢‘éŸ³é¢‘åˆå¹¶

```python
def merge_video_audio(video_path: str, audio_path: str, output_path: str):
    """ä½¿ç”¨FFmpegåˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘"""
    try:
        import subprocess
        
        # FFmpegå‘½ä»¤
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-i', audio_path,
            '-c:v', 'copy',
            '-c:a', 'copy',
            '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            output_path
        ]
        
        # æ‰§è¡Œåˆå¹¶
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            return True
        else:
            print(f"FFmpegé”™è¯¯: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"åˆå¹¶å¤±è´¥: {e}")
        return False
```

## ğŸ“Š çŠ¶æ€ç®¡ç†ç³»ç»Ÿ

### å…¨å±€çŠ¶æ€å®šä¹‰

```python
# src/core/state.py
# å…¨å±€ä»»åŠ¡ä¸ç»“æœï¼Œä¸åŸ app.py ä¸­çš„å…¨å±€å˜é‡ä¿æŒä¸€è‡´
tasks = []          # çˆ¬è™«ä»»åŠ¡åˆ—è¡¨
results = []        # çˆ¬è™«ç»“æœåˆ—è¡¨
task_counter = 0    # ä»»åŠ¡è®¡æ•°å™¨

# Bç«™ä¸‹è½½ä»»åŠ¡å­—å…¸
download_tasks = {}  # {task_id: {status, progress, file_path, error, ...}}
```

### ä»»åŠ¡çŠ¶æ€æµè½¬

```python
# ä»»åŠ¡çŠ¶æ€å®šä¹‰
TASK_STATUS = {
    'pending': 'ç­‰å¾…ä¸­',
    'running': 'æ‰§è¡Œä¸­', 
    'completed': 'å·²å®Œæˆ',
    'failed': 'å¤±è´¥',
    'cancelled': 'å·²å–æ¶ˆ'
}

# ä¸‹è½½ä»»åŠ¡çŠ¶æ€
DOWNLOAD_STATUS = {
    'waiting': 'ç­‰å¾…ä¸‹è½½',
    'downloading': 'ä¸‹è½½ä¸­',
    'merging': 'åˆå¹¶ä¸­',
    'completed': 'ä¸‹è½½å®Œæˆ',
    'error': 'ä¸‹è½½å¤±è´¥'
}
```

### ä»»åŠ¡ç®¡ç†API

```python
# src/api/stats.py
@stats_bp.route('/api/tasks')
def get_tasks():
    """è·å–æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨"""
    return jsonify({
        'success': True,
        'tasks': tasks,
        'total': len(tasks)
    })

@stats_bp.route('/api/task/<int:task_id>')
def get_task(task_id):
    """è·å–ç‰¹å®šä»»åŠ¡è¯¦æƒ…"""
    task = next((t for t in tasks if t['id'] == task_id), None)
    if task:
        return jsonify({'success': True, 'task': task})
    else:
        return jsonify({'success': False, 'message': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

@stats_bp.route('/api/results')
def get_results():
    """è·å–æ‰€æœ‰çˆ¬å–ç»“æœ"""
    return jsonify({
        'success': True,
        'results': results,
        'total': len(results)
    })
```

## ğŸ”„ WebSocketäº‹ä»¶ç³»ç»Ÿ

### äº‹ä»¶å®šä¹‰

```python
# ä¸‹è½½ç›¸å…³äº‹ä»¶
SOCKET_EVENTS = {
    'download_progress': 'ä¸‹è½½è¿›åº¦æ›´æ–°',
    'download_complete': 'ä¸‹è½½å®Œæˆ',
    'download_error': 'ä¸‹è½½é”™è¯¯',
    'task_status_change': 'ä»»åŠ¡çŠ¶æ€å˜æ›´',
    'system_notification': 'ç³»ç»Ÿé€šçŸ¥'
}
```

### äº‹ä»¶å‘é€

```python
from src.extensions import socketio

def emit_download_progress(task_id: str, progress_data: dict):
    """å‘é€ä¸‹è½½è¿›åº¦äº‹ä»¶"""
    socketio.emit('download_progress', {
        'task_id': task_id,
        'progress': progress_data['progress'],
        'speed': progress_data.get('speed', ''),
        'eta': progress_data.get('eta', ''),
        'downloaded': progress_data.get('downloaded', ''),
        'total': progress_data.get('total', '')
    })

def emit_task_complete(task_id: str, result_data: dict):
    """å‘é€ä»»åŠ¡å®Œæˆäº‹ä»¶"""
    socketio.emit('download_complete', {
        'task_id': task_id,
        'file_path': result_data.get('file_path', ''),
        'file_size': result_data.get('file_size', ''),
        'duration': result_data.get('duration', '')
    })

def emit_system_notification(message: str, type: str = 'info'):
    """å‘é€ç³»ç»Ÿé€šçŸ¥"""
    socketio.emit('system_notification', {
        'message': message,
        'type': type,  # info, success, warning, error
        'timestamp': datetime.now().isoformat()
    })
```

## ğŸ› ï¸ å·¥å…·å‡½æ•°åº“

### æ–‡ä»¶å¤§å°æ ¼å¼åŒ–

```python
def format_file_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.2f} {size_names[i]}"

def get_stream_file_size(url: str, headers: dict) -> str:
    """è·å–æµæ–‡ä»¶å¤§å°"""
    try:
        response = requests.head(url, headers=headers, timeout=10)
        content_length = response.headers.get('content-length')
        if content_length:
            return format_file_size(int(content_length))
        return "æœªçŸ¥å¤§å°"
    except:
        return "æœªçŸ¥å¤§å°"
```

### è§†é¢‘è´¨é‡æ˜ å°„

```python
def get_quality_desc(quality_id: int) -> str:
    """è·å–è§†é¢‘è´¨é‡æè¿°"""
    quality_map = {
        120: "4K è¶…æ¸…",
        116: "1080P60 é«˜æ¸…",
        112: "1080P+ é«˜æ¸…", 
        80: "1080P é«˜æ¸…",
        74: "720P60 é«˜æ¸…",
        64: "720P é«˜æ¸…",
        32: "480P æ¸…æ™°",
        16: "360P æµç•…"
    }
    return quality_map.get(quality_id, f"è´¨é‡{quality_id}")
```

## ğŸ” é”™è¯¯å¤„ç†æœºåˆ¶

### ç»Ÿä¸€é”™è¯¯å¤„ç†

```python
class CrawlerError(Exception):
    """çˆ¬è™«åŸºç¡€å¼‚å¸¸ç±»"""
    def __init__(self, message: str, error_code: str = None):
        self.message = message
        self.error_code = error_code
        super().__init__(self.message)

class NetworkError(CrawlerError):
    """ç½‘ç»œè¯·æ±‚å¼‚å¸¸"""
    pass

class AuthError(CrawlerError):
    """è®¤è¯å¼‚å¸¸"""
    pass

class ParseError(CrawlerError):
    """è§£æå¼‚å¸¸"""
    pass

def handle_api_error(func):
    """APIé”™è¯¯å¤„ç†è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except CrawlerError as e:
            return jsonify({
                'success': False,
                'message': e.message,
                'error_code': e.error_code
            }), 400
        except Exception as e:
            return jsonify({
                'success': False,
                'message': f'ç³»ç»Ÿé”™è¯¯: {str(e)}',
                'error_code': 'SYSTEM_ERROR'
            }), 500
    return wrapper
```

### é‡è¯•æœºåˆ¶

```python
import time
from functools import wraps

def retry(max_attempts: int = 3, delay: float = 1.0, backoff: float = 2.0):
    """é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            attempts = 0
            current_delay = delay
            
            while attempts < max_attempts:
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    attempts += 1
                    if attempts >= max_attempts:
                        raise e
                    
                    print(f"ç¬¬{attempts}æ¬¡å°è¯•å¤±è´¥: {e}, {current_delay}ç§’åé‡è¯•")
                    time.sleep(current_delay)
                    current_delay *= backoff
            
            return None
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@retry(max_attempts=3, delay=1.0)
def fetch_video_info(bvid: str):
    # å¯èƒ½å¤±è´¥çš„ç½‘ç»œè¯·æ±‚
    pass
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. è¿æ¥æ± ç®¡ç†

```python
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

class OptimizedSession:
    """ä¼˜åŒ–çš„HTTPä¼šè¯ç®¡ç†"""
    
    def __init__(self):
        self.session = requests.Session()
        
        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504]
        )
        
        # é…ç½®é€‚é…å™¨
        adapter = HTTPAdapter(
            max_retries=retry_strategy,
            pool_connections=20,
            pool_maxsize=20
        )
        
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
    
    def get(self, url: str, **kwargs):
        return self.session.get(url, **kwargs)
    
    def post(self, url: str, **kwargs):
        return self.session.post(url, **kwargs)
```

### 2. ç¼“å­˜æœºåˆ¶

```python
import json
import hashlib
from datetime import datetime, timedelta

class SimpleCache:
    """ç®€å•å†…å­˜ç¼“å­˜"""
    
    def __init__(self, default_ttl: int = 300):
        self.cache = {}
        self.default_ttl = default_ttl
    
    def _generate_key(self, data: str) -> str:
        return hashlib.md5(data.encode()).hexdigest()
    
    def get(self, key: str):
        cache_key = self._generate_key(key)
        if cache_key in self.cache:
            item = self.cache[cache_key]
            if datetime.now() < item['expires']:
                return item['data']
            else:
                del self.cache[cache_key]
        return None
    
    def set(self, key: str, data, ttl: int = None):
        cache_key = self._generate_key(key)
        expires = datetime.now() + timedelta(seconds=ttl or self.default_ttl)
        self.cache[cache_key] = {
            'data': data,
            'expires': expires
        }
    
    def clear(self):
        self.cache.clear()

# å…¨å±€ç¼“å­˜å®ä¾‹
video_info_cache = SimpleCache(ttl=600)  # 10åˆ†é’Ÿç¼“å­˜
```

### 3. å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—

```python
import threading
from queue import Queue
from concurrent.futures import ThreadPoolExecutor

class TaskQueue:
    """å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†"""
    
    def __init__(self, max_workers: int = 5):
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.tasks = {}
    
    def submit_task(self, task_id: str, func, *args, **kwargs):
        """æäº¤å¼‚æ­¥ä»»åŠ¡"""
        future = self.executor.submit(func, *args, **kwargs)
        self.tasks[task_id] = {
            'future': future,
            'status': 'running',
            'start_time': datetime.now()
        }
        return task_id
    
    def get_task_status(self, task_id: str):
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        if task_id not in self.tasks:
            return None
        
        task = self.tasks[task_id]
        future = task['future']
        
        if future.done():
            if future.exception():
                task['status'] = 'failed'
                task['error'] = str(future.exception())
            else:
                task['status'] = 'completed'
                task['result'] = future.result()
        
        return task
    
    def cancel_task(self, task_id: str):
        """å–æ¶ˆä»»åŠ¡"""
        if task_id in self.tasks:
            future = self.tasks[task_id]['future']
            if future.cancel():
                self.tasks[task_id]['status'] = 'cancelled'
                return True
        return False

# å…¨å±€ä»»åŠ¡é˜Ÿåˆ—
task_queue = TaskQueue(max_workers=10)
```

## ğŸ”’ å®‰å…¨æœºåˆ¶

### 1. è¯·æ±‚é¢‘ç‡é™åˆ¶

```python
import time
from collections import defaultdict

class RateLimiter:
    """è¯·æ±‚é¢‘ç‡é™åˆ¶å™¨"""
    
    def __init__(self, max_requests: int = 60, time_window: int = 60):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = defaultdict(list)
    
    def is_allowed(self, identifier: str) -> bool:
        now = time.time()
        requests = self.requests[identifier]
        
        # æ¸…ç†è¿‡æœŸè¯·æ±‚
        requests[:] = [req_time for req_time in requests 
                      if now - req_time < self.time_window]
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if len(requests) >= self.max_requests:
            return False
        
        # è®°å½•æ–°è¯·æ±‚
        requests.append(now)
        return True
    
    def get_reset_time(self, identifier: str) -> float:
        requests = self.requests[identifier]
        if not requests:
            return 0
        return requests[0] + self.time_window

# å…¨å±€é™æµå™¨
rate_limiter = RateLimiter(max_requests=30, time_window=60)
```

### 2. è¾“å…¥éªŒè¯

```python
import re
from urllib.parse import urlparse

def validate_bvid(bvid: str) -> bool:
    """éªŒè¯Bç«™è§†é¢‘IDæ ¼å¼"""
    if not bvid:
        return False
    return bool(re.match(r'^BV[a-zA-Z0-9]{10}$', bvid))

def validate_url(url: str) -> bool:
    """éªŒè¯URLæ ¼å¼"""
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except:
        return False

def sanitize_filename(filename: str) -> str:
    """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
    # ç§»é™¤æˆ–æ›¿æ¢éæ³•å­—ç¬¦
    illegal_chars = r'[<>:"/\\|?*]'
    filename = re.sub(illegal_chars, '_', filename)
    
    # é™åˆ¶é•¿åº¦
    if len(filename) > 200:
        filename = filename[:200]
    
    return filename.strip()
```

## ğŸ“ æ€»ç»“

æœ¬æ–‡æ¡£è¯¦ç»†è§£æäº†NYLGçˆ¬è™«ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½å®ç°ï¼ŒåŒ…æ‹¬ï¼š

1. **è®¤è¯ç³»ç»Ÿ**: Bç«™äºŒç»´ç ç™»å½•çš„å®Œæ•´æµç¨‹
2. **ä¸‹è½½ç³»ç»Ÿ**: å¼‚æ­¥è§†é¢‘ä¸‹è½½å’Œåˆå¹¶æœºåˆ¶
3. **çŠ¶æ€ç®¡ç†**: å…¨å±€çŠ¶æ€å’Œä»»åŠ¡ç®¡ç†
4. **å®æ—¶é€šä¿¡**: WebSocketäº‹ä»¶ç³»ç»Ÿ
5. **å·¥å…·å‡½æ•°**: æ–‡ä»¶å¤„ç†å’Œæ ¼å¼åŒ–å·¥å…·
6. **é”™è¯¯å¤„ç†**: ç»Ÿä¸€å¼‚å¸¸å¤„ç†å’Œé‡è¯•æœºåˆ¶
7. **æ€§èƒ½ä¼˜åŒ–**: ç¼“å­˜ã€è¿æ¥æ± ã€ä»»åŠ¡é˜Ÿåˆ—
8. **å®‰å…¨æœºåˆ¶**: é¢‘ç‡é™åˆ¶å’Œè¾“å…¥éªŒè¯

è¿™äº›æ ¸å¿ƒåŠŸèƒ½å…±åŒæ„æˆäº†ä¸€ä¸ªç¨³å®šã€é«˜æ•ˆã€å®‰å…¨çš„ç½‘ç»œçˆ¬è™«ç³»ç»Ÿã€‚é€šè¿‡æ¨¡å—åŒ–è®¾è®¡å’Œå®Œå–„çš„é”™è¯¯å¤„ç†ï¼Œç³»ç»Ÿå…·å¤‡äº†è‰¯å¥½çš„å¯ç»´æŠ¤æ€§å’Œæ‰©å±•æ€§ã€‚

---

*ğŸ’¡ æç¤ºï¼šåœ¨å®é™…éƒ¨ç½²æ—¶ï¼Œå»ºè®®æ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´å„é¡¹å‚æ•°ï¼Œå¦‚ç¼“å­˜æ—¶é—´ã€é‡è¯•æ¬¡æ•°ã€å¹¶å‘æ•°é‡ç­‰ã€‚